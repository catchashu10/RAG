{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Bare minimum RAG to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the document about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG setup using Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 56402\n",
      "    })\n",
      "})\n",
      "Train dataset size: 42301\n",
      "Test dataset size: 14101\n",
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 42301\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 14101\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"toughdata/quora-question-answer-dataset\")\n",
    "print(ds)\n",
    "# Extract the corpus\n",
    "corpus = ds['train']['answer']\n",
    "\n",
    "# Split the dataset\n",
    "split = ds['train'].train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "# Access the train and test splits\n",
    "train_ds = split['train']\n",
    "test_ds = split['test']\n",
    "\n",
    "# Print the details\n",
    "print(f\"Train dataset size: {len(train_ds)}\")\n",
    "print(f\"Test dataset size: {len(test_ds)}\")\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1763/1763 [00:34<00:00, 50.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0786,  0.0242,  0.0263,  ...,  0.0464, -0.1054,  0.0366],\n",
      "        [-0.0498, -0.0341,  0.0440,  ...,  0.0381, -0.0093, -0.0391],\n",
      "        [ 0.0365,  0.0454,  0.0159,  ...,  0.0293, -0.0735,  0.0448],\n",
      "        ...,\n",
      "        [-0.0756,  0.0891, -0.0266,  ..., -0.0312, -0.0291,  0.0853],\n",
      "        [-0.0277,  0.0797,  0.0494,  ..., -0.0381, -0.0556,  0.0960],\n",
      "        [ 0.0438,  0.0441,  0.0684,  ..., -0.0912, -0.0427, -0.0391]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Generate embeddings\n",
    "embeddings = model.encode(corpus, batch_size=32, show_progress_bar=True, convert_to_tensor=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56402, 384])\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'corpus_id': 53619, 'score': 0.791310727596283}, {'corpus_id': 21947, 'score': 0.78010094165802}, {'corpus_id': 25515, 'score': 0.7756905555725098}, {'corpus_id': 34270, 'score': 0.7715657353401184}, {'corpus_id': 46198, 'score': 0.7709584832191467}]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "# Define a query\n",
    "query = \"What is a proxy, and how can I use one?\"\n",
    "\n",
    "# Encode the query\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# Perform semantic search\n",
    "top_k = 5  # Number of top answers to retrieve\n",
    "results = util.semantic_search(query_embedding, embeddings, top_k=top_k)[0]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is a proxy, and how can I use one?\n",
      "\n",
      "Rank 1:\n",
      "Answer: What is a Proxy?\n",
      " A proxy can be defined as software that makes requests to the server on behalf of the clients. In simple words, the proxy sits between the clients and the servers. Any request from the user first goes through the proxy and then reaches the server. This is also known as \"forward proxy\".\n",
      " The system or router on which this software sits is known as a Proxy Server.\n",
      "How does a proxy work?\n",
      " As mentioned, proxies are an intermediary that sits between a user's browser and a website, routing the requests through their own machine. It can be thought of as if proxies act as a filter between users and the server. Any request from the user first goes through the proxy and then reaches the server.\n",
      " They also provide a level of anonymity, often required by people who do not want their browsing history to be tracked by their ISPs. Proxies are also used to allow users to access sites they would not normally be able to reach.\n",
      " If you want to know more about a proxy, checkout this article titled - â€œWhat is a Proxy? The difference between a proxy and a reverse proxy. Use cases of proxies.â€\n",
      "[LINKED_TEXT: The Complete Guide to Proxies. Difference between a proxy and a reverse proxy. Types of proxies - The Geeky MindsA proxy can be defined as a software that makes requests to the server on behalf of the clients. In simple words, the proxy sits between the clients and the servers. Any request from the user first goes through the proxy and then reaches the server. This is also known as \"forward proxy\".https://www.thegeekyminds.com/post/what-is-a-proxy-the-difference-between-a-proxy-and-a-reverse-proxy-use-cases-of-proxies] [URL: https://www.thegeekyminds.com/post/what-is-a-proxy-the-difference-between-a-proxy-and-a-reverse-proxy-use-cases-of-proxies]\n",
      "Score: 0.7913\n",
      "\n",
      "Rank 2:\n",
      "Answer: A proxy server acts as an intermediary between a client computer and the internet, allowing requests to be fulfilled or passed on while improving performance and providing anonymity.\n",
      "\n",
      "Score: 0.7801\n",
      "\n",
      "Rank 3:\n",
      "Answer: In computer networking, a proxy server is a server application or appliance that acts as an intermediary for requests from clients seeking resources from servers that provide those resources you can buy proxy with the link below ðŸ‘‡ðŸ‘‡ðŸ‘‡and get 20% discount code (yB6Ydq5)\n",
      " [LINKED_TEXT: Buy proxy. Personal anonymous IPv4/IPv6 proxies] [URL: https://bit.ly/2NrNNTK]\n",
      "\n",
      "Score: 0.7757\n",
      "\n",
      "Rank 4:\n",
      "Answer: A proxy server is arguably a remote computer that is used to restrict Internet access, filter content, and make Internet browsing more secure. It acts as a middleman between the end user and the web server, as all connections are via it.\n",
      " A proxy server works by filtering requests first, then sends them to the web server. Once the web server responds, the proxy filters the response then relays to the end user.\n",
      "\n",
      "Score: 0.7716\n",
      "\n",
      "Rank 5:\n",
      "Answer: A proxy server is a computer that acts as an intermediary between your computer and the Internet. When you access the Internet, your computer will first connect to the proxy server, which will then connect to the website you want to access. The proxy server will then send the website information back to your computer.\n",
      "Proxy servers can be used for a variety of purposes, such as to improve security or to filter content. When used for security, a proxy server can help to protect your computer from malware or hackers. By filtering content, a proxy server can block websites that contain offensive or illegal content.\n",
      " There are a few different types of proxy servers, including web proxies, application proxies, and SOCKS proxies. Web proxies are the most common type of proxy server. They can be used to access websites that are blocked by your ISP or firewall. Application proxies can be used to access specific applications that are blocked. SOCKS proxies can be used to access any type of Internet traffic, including email, chat, and file sharing.\n",
      " Proxy servers can be configured in a number of ways. They can be configured to allow or deny access to specific websites or IP addresses. They can also be configured to use different ports for different types of traffic.\n",
      " For more information, please visit the website:\n",
      "[LINKED_TEXT: Best Proxy Services of 2023 - Ultimate Proxy Comparisons | Stupid ProxyThe Ultimate Proxy Comparisons and in-depth guides to help you find the best proxy service to match your Online marketing, Security and Privacy requirement.https://www.stupidproxy.com/best-proxy/] [URL: https://www.stupidproxy.com/best-proxy/]\n",
      "Score: 0.7710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top-k results\n",
    "print(f\"Query: {query}\\n\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Rank {i + 1}:\")\n",
    "    print(f\"Answer: {corpus[result['corpus_id']]}\")\n",
    "    print(f\"Score: {result['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Accuracy: 0.1933\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "def evaluate_model(questions, answers, corpus, corpus_embeddings, model, top_k=5):\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of the embedding model by checking if the correct answer \n",
    "    is in the top-k retrieved results for each question.\n",
    "    \n",
    "    Parameters:\n",
    "    - questions: List of questions to query.\n",
    "    - answers: List of corresponding correct answers for the questions.\n",
    "    - corpus: List of all answers in the corpus.\n",
    "    - corpus_embeddings: Precomputed embeddings for the corpus.\n",
    "    - model: The SentenceTransformer model.\n",
    "    - top_k: Number of top results to consider for accuracy calculation.\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy: The overall accuracy of the model.\n",
    "    \"\"\"\n",
    "    correct_count = 0\n",
    "    total_questions = len(questions)\n",
    "\n",
    "    for i, question in enumerate(questions):\n",
    "        # Encode the query\n",
    "        query_embedding = model.encode(question, convert_to_tensor=True)\n",
    "\n",
    "        # Perform semantic search\n",
    "        results = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k)[0]\n",
    "\n",
    "        # Check if the correct answer is in the top-k results\n",
    "        correct_answer = answers[i]\n",
    "        retrieved_answers = [corpus[result['corpus_id']] for result in results]\n",
    "\n",
    "        if correct_answer in retrieved_answers:\n",
    "            correct_count += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_count / total_questions\n",
    "    return accuracy\n",
    "\n",
    "# Extract questions and corresponding answers from the test set\n",
    "test_questions = test_ds['question']\n",
    "test_answers = test_ds['answer']\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = evaluate_model(test_questions, test_answers, corpus, embeddings, model, top_k=5)\n",
    "print(f\"Top-5 Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternatively using the OpenAI context processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from context_processor import ContextProcessor\n",
    "\n",
    "def evaluate_model(questions, answers, corpus, corpus_embeddings, model, top_k=5):\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of the embedding model by checking if the correct answer \n",
    "    is in the top-k retrieved results for each question.\n",
    "    \n",
    "    Parameters:\n",
    "    - questions: List of questions to query.\n",
    "    - answers: List of corresponding correct answers for the questions.\n",
    "    - corpus: List of all answers in the corpus.\n",
    "    - corpus_embeddings: Precomputed embeddings for the corpus.\n",
    "    - model: The SentenceTransformer model.\n",
    "    - top_k: Number of top results to consider for accuracy calculation.\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy: The overall accuracy of the model.\n",
    "    \"\"\"\n",
    "    # Initialize context processor with OpenAI model\n",
    "    context_processor = ContextProcessor(\n",
    "        llm=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "    )\n",
    "    \n",
    "    correct_count = 0\n",
    "    total_questions = len(questions)\n",
    "\n",
    "    for i, question in enumerate(questions):\n",
    "        # Encode the query\n",
    "        query_embedding = model.encode(question, convert_to_tensor=True)\n",
    "\n",
    "        # Perform semantic search\n",
    "        results = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k)[0]\n",
    "\n",
    "        # Convert to Documents with metadata and extract retrieved answers\n",
    "        retrieved_docs = []\n",
    "        retrieved_answers = []\n",
    "        for result in results:\n",
    "            retrieved_answers.append(corpus[result['corpus_id']])\n",
    "            retrieved_docs.append(Document(\n",
    "                page_content=corpus[result['corpus_id']],\n",
    "                metadata={\n",
    "                    'corpus_id': result['corpus_id'],\n",
    "                    'score': result['score']\n",
    "                }\n",
    "            ))\n",
    "        \n",
    "        # Process documents using context processor\n",
    "        processed_docs = context_processor.process_documents(\n",
    "            documents=retrieved_docs,\n",
    "            query=question\n",
    "        )\n",
    "        \n",
    "        # Extract processed answers\n",
    "        processed_answers = [doc.page_content for doc in processed_docs]\n",
    "            \n",
    "        # Check if the correct answer is in either the original or processed results\n",
    "        correct_answer = answers[i]\n",
    "        \n",
    "        # Check against both original and processed answers\n",
    "        if (correct_answer in retrieved_answers) or (correct_answer in processed_answers):\n",
    "            correct_count += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_count / total_questions\n",
    "    return accuracy\n",
    "\n",
    "# Extract questions and corresponding answers from the test set\n",
    "test_questions = test_ds['question']\n",
    "test_answers = test_ds['answer']\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = evaluate_model(test_questions, test_answers, corpus, embeddings, model, top_k=5)\n",
    "print(f\"Top-5 Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base accuraacy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
