{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument for field google.cloud.aiplatform.v1.PredictRequest.instances is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m instance \u001b[38;5;241m=\u001b[39m json_format\u001b[38;5;241m.\u001b[39mParseDict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}, Value())\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create the request\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[43maiplatform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgapic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPredictRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Get the response\u001b[39;00m\n\u001b[1;32m     28\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mpredict(request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag/lib/python3.10/site-packages/proto/message.py:734\u001b[0m, in \u001b[0;36mMessage.__init__\u001b[0;34m(self, mapping, ignore_unknown_fields, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m         params[key] \u001b[38;5;241m=\u001b[39m pb_value\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Create the internal protocol buffer.\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_pb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpb\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument for field google.cloud.aiplatform.v1.PredictRequest.instances is not iterable"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "\n",
    "# Initialize the Vertex AI client\n",
    "client = aiplatform.gapic.PredictionServiceClient()\n",
    "\n",
    "# Specify the endpoint\n",
    "endpoint = client.endpoint_path(\n",
    "    project='foundation-models-437505',\n",
    "    location='us-central1',\n",
    "    endpoint='meta/llama-3.2-90b-vision-instruct-maas'  # Replace with your actual Endpoint ID\n",
    ")\n",
    "\n",
    "# Prepare the prompt\n",
    "prompt = \"Your prompt here\"\n",
    "\n",
    "# Format the instance\n",
    "instance = json_format.ParseDict({\"content\": prompt}, Value())\n",
    "\n",
    "# Create the request\n",
    "request = aiplatform.gapic.PredictRequest(\n",
    "    endpoint=endpoint,\n",
    "    instances=[instance]\n",
    ")\n",
    "\n",
    "# Get the response\n",
    "response = client.predict(request=request)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Request failed with status code 401: [{\n  \"error\": {\n    \"code\": 401,\n    \"message\": \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.\",\n    \"status\": \"UNAUTHENTICATED\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\n        \"reason\": \"ACCESS_TOKEN_TYPE_UNSUPPORTED\",\n        \"metadata\": {\n          \"method\": \"google.cloud.aiplatform.v1beta1.PredictionService.ChatCompletions\",\n          \"service\": \"aiplatform.googleapis.com\"\n        }\n      }\n    ]\n  }\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m project_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfoundation-models-437505\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your Google Cloud project ID\u001b[39;00m\n\u001b[1;32m     47\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescribe the image content.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 48\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_llama_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[0;32mIn[4], line 43\u001b[0m, in \u001b[0;36mget_llama_response\u001b[0;34m(prompt, project_id, region)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest failed with status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Request failed with status code 401: [{\n  \"error\": {\n    \"code\": 401,\n    \"message\": \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.\",\n    \"status\": \"UNAUTHENTICATED\",\n    \"details\": [\n      {\n        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\n        \"reason\": \"ACCESS_TOKEN_TYPE_UNSUPPORTED\",\n        \"metadata\": {\n          \"method\": \"google.cloud.aiplatform.v1beta1.PredictionService.ChatCompletions\",\n          \"service\": \"aiplatform.googleapis.com\"\n        }\n      }\n    ]\n  }\n}\n]"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_llama_response(prompt, project_id, region='us-central1'):\n",
    "    # Define the API endpoint\n",
    "    endpoint = f'https://{region}-aiplatform.googleapis.com/v1beta1/projects/{project_id}/locations/{region}/endpoints/openapi/chat/completions'\n",
    "    \n",
    "    # Obtain an access token\n",
    "    access_token = '4/0AeanS0Yv51_yueLk3creLRCAUi8gvwJAqPLVzAXTdSBKG9l4fKNAC3Qeek9-qobuXbb3tw'  # Replace with your access token\n",
    "    \n",
    "    # Set up headers\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {access_token}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    # Define the payload\n",
    "    payload = {\n",
    "        'model': 'meta/llama-3.2-90b-vision-instruct-maas',\n",
    "        'stream': False,\n",
    "        'messages': [\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': [\n",
    "                    {'text': prompt, 'type': 'text'}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        'max_tokens': 40,\n",
    "        'temperature': 0.4,\n",
    "        'top_k': 10,\n",
    "        'top_p': 0.95,\n",
    "        'n': 1\n",
    "    }\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(endpoint, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    # Check for successful response\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"Request failed with status code {response.status_code}: {response.text}\")\n",
    "\n",
    "# Example usage\n",
    "project_id = 'foundation-models-437505'  # Replace with your Google Cloud project ID\n",
    "prompt = \"Describe the image content.\"\n",
    "response = get_llama_response(prompt, project_id)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ENDPOINT=us-central1-aiplatform.googleapis.com\n",
    "!REGION=us-central1\n",
    "!PROJECT_ID=\"foundation-models-437505\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:26\u001b[0;36m\u001b[0m\n\u001b[0;31m    }'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "curl -X POST -H \"Authorization: Bearer ${ACCESS_TOKEN}\" -H \"Content-Type: application/json\" https://${ENDPOINT}/v1beta1/projects/${PROJECT_ID}/locations/${REGION}/endpoints/openapi/chat/completions  -d '{\"model\": \"meta/llama-3.2-90b-vision-instruct-maas\",\"stream\": false,\"messages\": [{\"role\": \"user\",\"content\": [{\"image_url\": {\"url\": \"https://www.google.com/url?sa=i&url=https%3A%2F%2Fdefenders.org%2Fwildlife%2Fdolphins&psig=AOvVaw2FGHZ2muogC0nlckPBoXn2&ust=1733127607832000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCMil6syRhooDFQAAAAAdAAAAABAE\"},\"type\": \"image_url\"},{\"text\": \"Whatâ€™s in this image?\",\"type\": \"text\"}]}],\"max_tokens\": 40,\"temperature\": 0.4,\"top_k\": 10,\"top_p\": 0.95,\"n\": 1}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are running on a Google Compute Engine virtual machine.\n",
      "The service credentials associated with this virtual machine\n",
      "will automatically be used by Application Default\n",
      "Credentials, so it is not necessary to use this command.\n",
      "\n",
      "If you decide to proceed anyway, your user credentials may be visible\n",
      "to others with access to this virtual machine. Are you sure you want\n",
      "to authenticate with your personal account?\n",
      "\n",
      "Do you want to continue (Y/n)?  ^C\n",
      "\n",
      "\n",
      "Command killed by keyboard interrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
