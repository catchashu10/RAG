{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Bare minimum RAG to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex, SimpleDirectoryReader\n\u001b[1;32m      3\u001b[0m documents \u001b[38;5;241m=\u001b[39m SimpleDirectoryReader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m      4\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_documents(documents)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index'"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data/\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the document about?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG setup using Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/catch/miniconda3/envs/ashu_rag/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'answer'],\n",
      "        num_rows: 56402\n",
      "    })\n",
      "})\n",
      "Train dataset size: 42301\n",
      "Test dataset size: 14101\n",
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 42301\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 14101\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"toughdata/quora-question-answer-dataset\")\n",
    "print(ds)\n",
    "# Extract the corpus\n",
    "corpus = ds['train']['answer']\n",
    "\n",
    "# Split the dataset\n",
    "split = ds['train'].train_test_split(test_size=0.25, seed=42)\n",
    "\n",
    "# Access the train and test splits\n",
    "train_ds = split['train']\n",
    "test_ds = split['test']\n",
    "\n",
    "# Print the details\n",
    "print(f\"Train dataset size: {len(train_ds)}\")\n",
    "print(f\"Test dataset size: {len(test_ds)}\")\n",
    "\n",
    "print(train_ds)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 1. Load a pretrained Sentence Transformer model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 2. Generate embeddings\n",
    "embeddings = model.encode(corpus, batch_size=32, show_progress_bar=True, convert_to_tensor=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43membeddings\u001b[49m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(embeddings)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "print(embeddings.size())\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'corpus_id': 13692, 'score': 0.5951582193374634}, {'corpus_id': 43411, 'score': 0.5779244899749756}, {'corpus_id': 36884, 'score': 0.5605567693710327}, {'corpus_id': 16122, 'score': 0.5474002957344055}, {'corpus_id': 55635, 'score': 0.5435165762901306}]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "# Define a query\n",
    "query = \"What is an iPhone?\"\n",
    "\n",
    "# Encode the query\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# Perform semantic search\n",
    "top_k = 5  # Number of top answers to retrieve\n",
    "results = util.semantic_search(query_embedding, embeddings, top_k=top_k)[0]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is an iPhone?\n",
      "\n",
      "Rank 1:\n",
      "Answer: My opinion is the iPhone\n",
      "\n",
      "Score: 0.5952\n",
      "\n",
      "Rank 2:\n",
      "Answer: to operate the ios\n",
      "\n",
      "Score: 0.5779\n",
      "\n",
      "Rank 3:\n",
      "Answer: One of the most iconic business maneuvers is the strategic decision made by Apple Inc. in 2007 to introduce the iPhone. At the time, Apple was already an established player in the personal computer and portable music player markets. However, the iPhone represented a major shift in the company's focus, as it entered the highly competitive and rapidly evolving mobile phone market.\n",
      " Apple's decision to enter the mobile phone market was a calculated move based on a deep understanding of consumer needs and behavior. By introducing a product that combined the functions of a phone, music player, camera, and internet device, Apple created a new category of product that revolutionized the industry.\n",
      " The iPhone's success can be attributed to several factors, including its sleek design, intuitive user interface, and ecosystem of third-party apps. Apple's shrewd business maneuver helped it to establish itself as a dominant player in the mobile phone market and paved the way for future innovations, such as the iPad and Apple Watch.\n",
      " Read More: [LINKED_TEXT: Business Ideas, financial tips and Business Insurance] [URL: http://mayonfinance.com/]\n",
      "\n",
      "Score: 0.5606\n",
      "\n",
      "Rank 4:\n",
      "Answer: There are numerous iPhone apps available that cater to different interests and needs. The \"must-have\" apps can vary depending on individual preferences, but here are some popular and widely recommended apps that serve various purposes:\n",
      " Social Media Apps (e.g., Facebook, Instagram, Twitter): These apps allow you to connect with friends, share updates, and stay updated with current events and trends.\n",
      " Messaging Apps (e.g., WhatsApp, Telegram, Signal): These apps enable instant messaging, voice calls, and video chats with friends and family, offering a convenient way to stay in touch.\n",
      " Productivity Apps (e.g., Microsoft Office, Google Drive, Evernote): These apps help you manage your tasks, create documents, store files, and take notes on the go, enhancing productivity and organization.\n",
      " To know full information Please [LINKED_TEXT: Read Full Article] [URL: https://www.pindropbd.com/2023/06/the-incredible-iphone-15-future-of.html]..\n",
      "\n",
      "Score: 0.5474\n",
      "\n",
      "Rank 5:\n",
      "Answer: The iPhone's adaptability and use are enormously amplified by the huge swath of applications available on the Application Store. While there are endless applications taking exceptional care of various necessities, the ones referenced past stand apart as must-have iPhone applications because of their capacity to boost social institutions, efficiency, recreation, well-being, travel, and money the executives. As the application environment keeps on advancing, these applications will probably stay at the front of upgrading the general iPhone client knowledge.\n",
      " for more variable information you can visit here. Thank you!\n",
      "[LINKED_TEXT: The Development of the iPhone Business: A Mechanical OdysseyWelcome to News Experiences, your go-to hotspot for clear and ideal updates on worldwide events, legislative issues, innovation, and well-beinghttps://newsever4.blogspot.com/2023/07/the-development-of-iphone-business.html] [URL: https://newsever4.blogspot.com/2023/07/the-development-of-iphone-business.html]\n",
      "Score: 0.5435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top-k results\n",
    "print(f\"Query: {query}\\n\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Rank {i + 1}:\")\n",
    "    print(f\"Answer: {corpus[result['corpus_id']]}\")\n",
    "    print(f\"Score: {result['score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Accuracy: 0.1933\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "def evaluate_model(questions, answers, corpus, corpus_embeddings, model, top_k=5):\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of the embedding model by checking if the correct answer \n",
    "    is in the top-k retrieved results for each question.\n",
    "    \n",
    "    Parameters:\n",
    "    - questions: List of questions to query.\n",
    "    - answers: List of corresponding correct answers for the questions.\n",
    "    - corpus: List of all answers in the corpus.\n",
    "    - corpus_embeddings: Precomputed embeddings for the corpus.\n",
    "    - model: The SentenceTransformer model.\n",
    "    - top_k: Number of top results to consider for accuracy calculation.\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy: The overall accuracy of the model.\n",
    "    \"\"\"\n",
    "    correct_count = 0\n",
    "    total_questions = len(questions)\n",
    "\n",
    "    for i, question in enumerate(questions):\n",
    "        # Encode the query\n",
    "        query_embedding = model.encode(question, convert_to_tensor=True)\n",
    "\n",
    "        # Perform semantic search\n",
    "        results = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k)[0]\n",
    "\n",
    "        # Check if the correct answer is in the top-k results\n",
    "        correct_answer = answers[i]\n",
    "        retrieved_answers = [corpus[result['corpus_id']] for result in results]\n",
    "\n",
    "        if correct_answer in retrieved_answers:\n",
    "            correct_count += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_count / total_questions\n",
    "    return accuracy\n",
    "\n",
    "# Extract questions and corresponding answers from the test set\n",
    "test_questions = test_ds['question']\n",
    "test_answers = test_ds['answer']\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = evaluate_model(test_questions, test_answers, corpus, embeddings, model, top_k=5)\n",
    "print(f\"Top-5 Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base accuracy \n",
    "# Nick was here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
